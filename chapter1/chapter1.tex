% CHAPTER_BEGIN
\section{Ajira Framework: Research Report}

\subsection{Introduction}

The \textit{ajira} project represents a custom made framework for writing mainly HPC data applications. It is built as a framework on top of IPL (Ibis Portability Layer - communication layer) adopting a master-slave architecture. The master is basically another slave that hast the extra requirement to setup the communication and start splitting the job between all the nodes (slaves). Thus, we do not have to install and configure anything as a separate platform and then use a special API to run jobs/tasks on top of that platform (i.e such as using Hadoop). With other words, what we need to run an application is the \textit{ibis-server} (it is embedded inside the \textit{ajira} framework so we can run it from there and have our node communication layer) and, of course, a program that uses \textit{ajira} to compute some data. Usually, the program does not have to be divided into a master and slave architecture. We can only use \textit{ajira} framework to write the master section. The slaves' behavior is automatically dictated by the list of actions we add in the code, inside the job's description. For testing my experimental changes on \textit{ajira} I have run an application built with \textit{ajira} framework that sorts large data-sets of RDF triples. To build and run this entire setup (\textit{ajira} + \textit{sorting application}) I have used the git repository for code deployment on DAS4 and a self written ant file \cite{build_file} to build the application into a .jar bundle package (a package that embeds inside all the necessary dependencies, including the \textit{ajira.jar} package built with the default ant file). Next, to run the \textit{sorting application} on DAS4 was a simple \textit{prun} command execution (see next section).

% 
\subsection{Deployment \& execution on DAS4}

For \textit{ajira's} and \textit{sorting application's} main-code deployment on DAS4 you will first need access to their git repositories \cite{arch_repo}, \cite{qpie_repo}. After that, just simply clone the repositories in your home DAS4 directory and be sure that you are located in the benchm\_master branch. For the entire list of steps that you have to follow in order to run/execute this setup on multiple nodes, read next.
\newline
\newline
\textbf{Steps for running the \textit{sorting application} on multiple DAS4 cluster nodes:}
\begin{enumerate}
	\item Deploy \textit{ajira} and the \textit{demo sorting application} projects in your home DAS4 directory. Each project already has all the dependencies packages and ant files necessary for automatic build. 
	\item Build \textit{ajira} project using its ant build file: 'ant build-jar' 
	\item Copy the \textit{ajira.jar} package in the \textit{/lib} directory of the \textit{sorting app}
	\item Build \textit{sorting app} project using its ant build file \cite{build_file}: 'ant build-jar' (will create a .jar bundle package that we use to execute its main class - BenchmarkSorting - on DAS4; the .jar is placed by default in the \textit{/jar} directory -- for any change you wish to do look for the parameters inside the ant file)
	\item Configure \textit{ibis-server} parameters (port, enable events, etc) from inside \textit{ajira's} ant build file 
	\item Start \textit{ibis-server} on the DAS4 head-node from the \textit{ajira} project directory: 'ant ibis-server' (note the address and port that is using)
	\item Run/execute the bundle package on DAS4 using the script example \cite{run_on_das4} -- change the parameters for your own needs.
\end{enumerate}

% 
\subsection{Workflow example: how \textit{ajira} can be used to sort RDF triples}

In this section I will explain how the \textit{ajira} framework works on 'crunching' data, using as a workflow example the RDF triples' \textit{distributed sorting} implemented in the \textit{sorting example application}. To begin with, the process of sorting can be split in 3 steps: (1) read and sort the RDF triples; (2) send-receive communication; (3) merge and write the RDF triples in files;

The main data structure used in all three steps is the 'Bucket' -- an in-memory buffer that is filled up with triples of which hash keys are equal to the bucket's identifier. When the buffer limit size is exceeded, all its content gets sorted and cached on the hard-disk (in files). Thus, when we refer to the 'Bucket' we usually mean both the in-memory buffer and the hard-disk stored files (if data hits the disk). Each time the files' number increases above a fixed limit, a thread is started to merge them 2-by-2 up until their number gets below. All the information about the files (metadata such as names, first elements, size, etc) is kept inside the Bucket -- we need them at the time we transfer the triples or when we write the resulted set back. By default, each node keeps 1 bucket in the memory for every other node (remote-buckets), including itself (local-bucket). So, there are by default N buckets on each node, where N = number of nodes; a new feature allows you to use more than 1 bucket per node (NPARTITIONS\_PER\_NODE parameter, which by default is 1). The creation and initialization of a bucket (create, get, release, etc) is controlled by the 'Buckets' wrapper class.

% 
\subsubsection*{(1) Read and sort the RDF triples}

First, the data set (compressed or not) gets split into file partitions of almost the same sizes, each one being assigned to one node for further reading. The split of the data set is done by the ReadFromFiles action, which creates FileCollections of a minimumFileSplitSize. Next, the FileLayer of each node reads the triples from its assigned partitions -- the FileCollections (a set of path names representing the location of the files that were partitioned) -- and inserts them into the corresponding local/remote bucket (where the triple's hash key equals to the node's bucket id). If a bucket gets full with triples, its content is sorted using the java's default MergeSort algorithm and cached on disk. All the information/metadata about caching the content on the disk is stored inside the Bucket object model for further use. When there is no more data left to read from a partition, the node broadcasts a signal, alerting that the remote-buckets are ready to get transferred (this means that the send-receive start is dependent on the size of the file partition). See Figure~\ref{fig:diag1} for a better understanding. So, at this point, the send-receive step begins -- triples are transferred from the remote-buckets to their assigned nodes (i.e. on node Y, its remote-bucket for node X has triples assigned to X \textit{=>} triples from Y's remote-bucket will be transferred to X's local-bucket).

\begin{figure}
\centering
\includegraphics[scale=0.6]{diag1}
\caption{Read and sort - remote \& local buckets structure}
\label{fig:diag1}
\end{figure}

% 
\subsubsection*{(2) Send-receive communication}

When a signal alert for a bucket ready for transfer is received by a node (\textit{receiver}), a corespondent request for fetching triples from it is sent back to the \textit{sender}. Then, the \textit{sender} registers that request and, whenever the remote-bucket has the available data (MIN\_SIZE\_TO\_SEND) for transfer, removes a chunk and sends it to the \textit{requester}. Next, the \textit{recipient} adds that chunk into its local-bucket and \textit{sends} a request for another fetch. As long as on the other side (\textit{sender's} side) the remote-bucket still contains triples, the \textit{receiver} will have chunks get transferred in its local-bucket. If there are no more RDF triples inside of it, the remote-bucket is released and the transfer's metatada are cleaned/removed. But, before that, a last signal that marks the end of the transfer is sent to the \textit{recipient}, which flags its local-bucket with \textit{finished} -- meaning that is ready for merge \& write. In Figure~\ref{fig:diag2} we show very briefly the workflow of the send-receive communication. The chunk removal, in the worst case when triples are getting cached on the disk, has to extract all the minimum triples from the in-memory buffer and the cached files (in sorted order) up until it fills the chunk. Is necessary to do that because we expect to receive sorted data on the \textit{recipient} side. Otherwise, basically, it sends a chunk directly from the in-memory buffer, but after it applies the sort.

\begin{figure}
\centering
\includegraphics[scale=0.6]{diag2}
\caption{Transfer to correspondent nodes - send-receive communication}
\label{fig:diag2}
\end{figure}

% 
\subsubsection*{(3) Merge and write the RDF triples in files - results output}

After all the triples got moved from the remote-buckets (previous step is finished), the final step is all about merging the local-bucket's in-memory buffer with its cached content (the files from the hard disk, in case data hits the disk). This task is done by the same method (\textit{removeChunk()}) that removes chunks from a bucket. Now it stands for fetching data from the local-bucket whenever the bucket-iterator is called for writing data. In the end, the result at each node is represented by one sorted file with RDF triples (only if we let the default number, equal with 1, of buckets per node). This step is represented by Figure~\ref{fig:diag3}.

\begin{figure}
\centering
\includegraphics[scale=0.6]{diag3}
\caption{Merge and write}
\label{fig:diag3}
\end{figure}

\pagebreak

% 
\subsection{Execution-time}

Testing configuration: 
\begin{itemize}
	\item \textbf{Cluster-Node}: 1 Node @ DAS4, 16 x QuadCore Intel Xeon CPU E5620 @ 2.4GHz 
	\item \textbf{Number of Nodes}: 8, 12, 16
	\item \textbf{Dataset sizes}: 21, 38, 62, 149 GB
	\item \textbf{Split sizes}: 256MB, 1GB, 2GB, 4GB
	\item \textbf{Common setups}: 512MB buffer size, available to transmit on 128MB (1/4 of buffer size), 8 concurrent tuple senders
\end{itemize}

Test - 8 nodes
\newline \newline
\renewcommand{\arraystretch}{1.2}
{\footnotesize\tt
\input{results/8n.tex}
}

Test - 12 nodes
\newline \newline
\renewcommand{\arraystretch}{1.2}
{\footnotesize\tt
\input{results/12n.tex}
}

Test - 16 nodes
\newline \newline
\renewcommand{\arraystretch}{1.2}
{\footnotesize\tt
\input{results/16n.tex}
}

% 
\subsection{Proposals \& implementations: how to improve \textit{ajira's} \\ execution-time}

In generally, a distributed large scale data application is considered optimal if each data-item (in our case \textit{1 single RDF triple}) is processed (i.e \textit{distributed sorting}) using less than (inclusive) 2 writes on disk. Not so many applications apply this rule - including the \textit{ajira} framework (branch benchm\_master). In worst case, if we are dealing with a big amount of data (a file partition split size bigger than the size of our available buffer), the total number of disk writes sums up to 3 (1 write would be for reading/sorting/caching data on the disk + 1 on the recipient side for gathering data in the local-bucket and + 1 for writing the final results). Given the previous research I made on Hadoop's Map-Reduce \cite{hadoop}, a platform for processing data which has a layer for data \cite{shuffling} for partitioning it to the reducers, I came up with the following ideas: 
\begin{itemize}
\item to \textit{disable the local sorting of remote-buckets},
\item to \textit{start as soon as possible the triples' transfer/send-receive} (we do not need to keep data more than is necessary) and
\item to \textit{use an in-background double buffering mechanism to provide final merged chunks for the bucket-iterator}. 
\end{itemize}
  
These proposals intent to increase the chances of using less then 3 writes on disk (unless the network represents a bottleneck) and to improve the execution time of the \textit{ajira} framework. From the distributed-sorting point of view, in my opinion, this approach of moving the sort phase on the recipient side and having less writes on disks is able to improve the total time of the execution. In the next paragraphs I will detail each of them and also provide some implementation aspects.

% 
\subsubsection*{(1) Disabling sort property for remote-buckets}

Now, that we decided to begin the data transfer as soon as possible, we do not need anymore to apply a sorting algorithm on the remote-buckets before that (sooner we send the chunks into network, lower the chances to hit the disk would be). The sorting will have to be placed on the recipient side (local-bucket), under the same assumptions -- when the buffer gets filled, it gets sorted and cached on the disk. To disable this property, we have to construct/initialize the remote-buckets without a sorting function and sorting parameters.

% 
\subsubsection*{(2) Interleave the transfer with the local reading}

For the data transfer to start at the beginning, is obvious that it overlaps with the files-partition read phase. So, during startTransfer() call we should also start broadcasting signal alerts to the other nodes for sending back requests for fetching data -- alertTransfer() method. To allow that we have to accomplish the followings:

\textbf{(a) Allow receiving of unsorted data}
When a chunk is getting transferred (\textit{sendTuples() method}) we specify the sorting function and its parameters in the message. Because we do not apply anymore a sorting algorithm on the remote-buckets we now declare a null sorting function and parameters (meaning that the chunk is not sorted). Thus, on the recipient side we have to allow appending of unsorted data into the local-bucket. The original version of \textit{addAll()} method, which adds chunks into the local-bucket, used to expect sorted data -- it compares the size of the chunk with the size of the buffer and depending on which is bigger that one is being cached on the disk (\textit{cacheBuffer() method}). If it happens that the chunk is bigger, is cached directly without being sorted (because it was already done that on the sender side), otherwise it sorts the buffer and spills it on the disk. For the research part, this logic got changed a bit -- we now first try to add the chunk into the buffer, or the other way if the buffer has fewer elements, instead of writing directly onto the disk. Only if the addition fails, we sort and cache in a temporary file the one's content that has a bigger size.

\textbf{(b) Split the main buffer into two buffers}

Furthermore, we can improve the previous part by splitting the main buffer into two separate buffers in such way that one should be use for reading (\textit{inBuffer}) and one for receiving chunks (\textit{exBuffer}). In this way, we can operate independently on each buffer. One disadvantage is that we require extra memory for the second buffer. At the end of the transfer -- when the bucket is flagged with finished -- we add one buffer into another (\textit{combineInExBuffers()} method) in order to have a single buffer combined with both contents. If both have big sizes, one of them (the smaller one) gets cached on the disk.

\textbf{(c) Loosen-up the synchronization between bucket's methods}

Now, that we have managed to split the main buffer into two independent buffers we can further loosen-up the synchronization primitives between the read and transfer (\textit{add() and addAll() methods}), the only coarse synchronization point being the moment when both methods call \textit{cacheBuffer()} (both buffers might get full at the same time).

Steps 1 and 2 are described in Figure~\ref{fig:diag4}.

\pagebreak

\begin{figure}
\centering
\includegraphics[scale=0.6]{diag4a}
\linebreak
\linebreak
\centering
\includegraphics[scale=0.6]{diag4b}
\caption{New local/remote buckets}
\label{fig:diag4}
\end{figure}

% 
\subsubsection*{(3) Double-buffering for writing the results in files}

The last idea refers to writing down the sorted local-bucket (all the triples) into the final result file. This phase uses a \textit{bucketIterator} to iterate over the results. As in turn the iterator uses multiple \textit{removeChunk()} method calls to fetch chunks from the local-bucket, when there are no more triples to iterate/write down. An idea would be to hide the time that the iterator has to wait for merging-up triples from the main memory (buffer) with the ones stored on the disk. Instead we can try to remove/get a chunk that has been already processed and stored in a set of auxiliary buffers in memory (triples ready to be 'served' to the iterator). To implement that, we start a separate thread at the right moment we set the bucket's flag on finished to fill up auxiliary buffers with chunks from the main buffer. When a write is being performed the iterator is called and the chunk is taken directly from the auxiliary buffers instead of waiting for the whole merging. Moreover, when a buffer from the set gets emptied the thread will go on and try to refill it, if there are anymore triples for doing that -- this mechanism of storing buffers that were processed earlier is generally called 'Double-Buffering'. Figure~\ref{fig:diag5} shows how this mechanism was implemented for the \textit{removeChunk()}. 

\begin{figure}
\centering
\includegraphics[scale=0.6]{diag5}
\caption{In-background merge-up}
\label{fig:diag5}
\end{figure}

% 
\subsubsection{Results: execution-time}

Test - 8 nodes
\newline \newline
\renewcommand{\arraystretch}{1.2}
{\footnotesize\tt
\input{results/8n_r.tex}
}

\newpage

Test - 12 nodes
\newline \newline
\renewcommand{\arraystretch}{1.2}
{\footnotesize\tt
\input{results/12n_r.tex}
}

Test - 16 nodes
\newline \newline
\renewcommand{\arraystretch}{1.2}
{\footnotesize\tt
\input{results/16n_r.tex}
}

\newpage

Speedup test: average on the best 10 execution-times (mm.ss), see Figure~\ref{fig:speedup}
\newline \newline
\renewcommand{\arraystretch}{1.2}
{\footnotesize\tt
\input{results/speedup.tex}
}

\begin{figure}
\centering
\includegraphics[scale=0.6]{speedup}
\caption{Speedup-chart for Ajira[blue] \& Ajira-Research[red]}
\label{fig:speedup}
\end{figure}

% 
\subsubsection*{Discussion}

\subsection{Future work}

For future work I propose the following developments:

\begin{itemize}
	\item \textit{Moving to processes.} One idea is to implement an option/feature that allows specifying how many 'instances' of PartitionToNodes to run locally and how many remotely on other nodes (following the Apache design model, i.e multiple mappers on same node). Example: if 1 node has 4 x QuadCore CPUs --- in total we can run 8 instances at least (maximum 16), 2 local instances on every node (given the fact that one instance makes highly use of multi-threading is fair enough to start only 2 processes per node).
	\item \textit{Thread synchronization.} In Ajira framework we use threads for background processing and all the methods tend to be globally synchronized for avoiding race conditions on the data structures. This adds a significant overhead to the application, because the access to the data structures becomes coarse grained. A solution for that is to use fine-grained/free-locks data structures or a similar mechanism with double buffering. 
	\item \textit{Fine-grained file splitting.} For the current Ajira version we coarsely split the data set between nodes. That means we consider an entire file when we decide where to send it (in what split collection), for further computation, instead of splitting the file in multiple pieces (i.e 64MB) and take their sizes into consideration. For small size files (with an order of maximum tens of MB) the coarse grained level works fine, but if the dataset has bigger files in small numbers we can get into an unbalanced situation.
	\item \textit{Data sampling.} In the current state of Ajira, the output of a distributed sorting application is not globally ordered. It means that we still have to merge each result file in order to get a full sorted data set from the start to its end. Instead of that, a well known method to achieve global ordering and also a fair data balancing is to perform a previous step called \textit{sampling}. As a state-of-the-art idea is to rely on a Trie (a prefix tree) based algorithm with a depth level fixed in such a way that will assure you enough granularity to equally balance the key partitions to all your nodes. After you have computed the tree you will use that as a tuple partitioner instead of a hash algorithm in your normal data computation. An example of a Trie based sampling algorithm applied with Hadoop Map-Reduce can be seen at \cite{terasort}.
\end{itemize}

\subsection{Conclusions}
% CHAPTER_END